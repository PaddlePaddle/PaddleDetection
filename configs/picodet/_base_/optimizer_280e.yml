epoch: 280

LearningRate:
  base_lr: 0.4
  schedulers:
  - !CosineDecay
    max_epochs: 280
  - !LinearWarmup
    start_factor: 0.1
    steps: 300

OptimizerBuilder:
  optimizer:
    momentum: 0.9
    type: Momentum
  regularizer:
    factor: 0.0001
    type: L2
