epoch: 300

LRScheduler:
  name: LearningRate
  learning_rate: 0.32
  schedulers:
  - name: CosineDecay
    max_epochs: 300
  - name: LinearWarmup
    start_factor: 0.1
    steps: 300

Optimizer:
  name: OptimizerBuilder
  optimizer:
    momentum: 0.9
    name: Momentum
  regularizer:
    factor: 0.00004
    name: L2
