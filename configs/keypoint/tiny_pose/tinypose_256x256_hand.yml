use_gpu: true
log_iter: 5
save_dir: output
snapshot_epoch: 10
weights: output/tinypose_256x256_hand/model_final
epoch: 210
num_joints: &num_joints 21
pixel_std: &pixel_std 200
metric: KeyPointTopDownCOCOWholeBadyHandEval
num_classes: 1
train_height: &train_height 256
train_width: &train_width 256
trainsize: &trainsize [*train_width, *train_height]
hmsize: &hmsize [64, 64]
flip_perm: &flip_perm []


#####model
architecture: TopDownHRNet

TopDownHRNet:
  backbone: LiteHRNet
  post_process: HRNetPostProcess
  flip_perm: *flip_perm
  num_joints: *num_joints
  width: &width 40
  loss: KeyPointMSELoss
  use_dark: true

LiteHRNet:
  network_type: wider_naive
  freeze_at: -1
  freeze_norm: false
  return_idx: [0]

KeyPointMSELoss:
  use_target_weight: true
  loss_scale: 1.0


#####optimizer
LearningRate:
  base_lr: 0.002
  schedulers:
  - !PiecewiseDecay
    milestones: [170, 200]
    gamma: 0.1
  - !LinearWarmup
    start_factor: 0.001
    steps: 500

OptimizerBuilder:
  optimizer:
    type: Adam
  regularizer:
    factor: 0.0
    type: L2


#####data
TrainDataset:
  !KeypointTopDownCocoWholeBodyHandDataset
    image_dir: train2017
    anno_path: annotations/coco_wholebody_train_v1.0.json
    dataset_dir: dataset/coco
    num_joints: *num_joints
    trainsize: *trainsize
    pixel_std: *pixel_std

EvalDataset:
  !KeypointTopDownCocoWholeBodyHandDataset
    image_dir: val2017
    anno_path: annotations/coco_wholebody_val_v1.0.json
    dataset_dir: dataset/coco
    num_joints: *num_joints
    trainsize: *trainsize
    pixel_std: *pixel_std

TestDataset:
  !ImageFolder
    anno_path: dataset/coco/keypoint_imagelist.txt

worker_num: 2
global_mean: &global_mean [0.485, 0.456, 0.406]
global_std: &global_std [0.229, 0.224, 0.225]
TrainReader:
  sample_transforms:
    - TopDownRandomShiftBboxCenter:
        shift_prob: 0.3
        shift_factor: 0.16
    - TopDownRandomFlip:
        flip_prob: 0.5
        flip_perm: *flip_perm
    - TopDownGetRandomScaleRotation:
        rot_prob: 0.6
        rot_factor: 90
        scale_factor: 0.3
    # - AugmentationbyInformantionDropping:
    #     prob_cutout: 0.5
    #     offset_factor: 0.05
    #     num_patch: 1
    #     trainsize: *trainsize
    - TopDownAffine:
        trainsize: *trainsize
        use_udp: true
    - ToHeatmapsTopDown_DARK:
        hmsize: *hmsize
        sigma: 2
  batch_transforms:
    - NormalizeImage:
        mean: *global_mean
        std: *global_std
        is_scale: true
    - Permute: {}
  batch_size: 128
  shuffle: true
  drop_last: false

EvalReader:
  sample_transforms:
    - TopDownAffine:
        trainsize: *trainsize
        use_udp: true
  batch_transforms:
    - NormalizeImage:
        mean: *global_mean
        std: *global_std
        is_scale: true
    - Permute: {}
  batch_size: 128

TestReader:
  inputs_def:
    image_shape: [3, *train_height, *train_width]
  sample_transforms:
    - Decode: {}
    - TopDownEvalAffine:
        trainsize: *trainsize
    - NormalizeImage:
        mean: *global_mean
        std: *global_std
        is_scale: true
    - Permute: {}
  batch_size: 1
  fuse_normalize: false
