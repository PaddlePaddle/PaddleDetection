_BASE_: [
  '../../runtime.yml',
  '../../rtdetr/_base_/rtdetr_r50vd.yml',
  '../../rtdetr/_base_/rtdetr_reader.yml',
]

#for debug
eval_interval: 4000
save_interval: 4000
weights: output/rt_detr_ssod/model_final
find_unused_parameters: True
save_dir: output
log_iter: 50
ssod_method: Trainer_Semi_detr
### global config
use_simple_ema: True
ema_decay: 0.9996
use_gpu: true

### reader config
worker_num: 4

SemiTrainReader:
  sample_transforms:
    - Decode: {}
    - RandomDistort: {prob: 0.8}
    - RandomExpand: {fill_value: [0., 0., 0.]}
    - RandomCrop: {prob: 0.8}
    - RandomFlip: {}
  weak_aug:
    - RandomFlip: {prob: 0.0}
  strong_aug:
    - StrongAugImage: {transforms: [
        RandomColorJitter: {prob: 0.8, brightness: 0.4, contrast: 0.4, saturation: 0.4, hue: 0.1},
        RandomErasingCrop: {},
        RandomGaussianBlur: {prob: 0.5, sigma: [0.1, 2.0]},
        RandomGrayscale: {prob: 0.2},
      ]}
  sup_batch_transforms:
    - BatchRandomResize_semi_detr: {target_size: [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], random_size: True, random_interp: True, keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - NormalizeBox: {}
    - BboxXYXY2XYWH: {}
    - Permute: {}
  unsup_batch_transforms:
    - BatchRandomResize_semi_detr: {target_size: [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], random_size: True, random_interp: True, keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - NormalizeBox: {}
    - BboxXYXY2XYWH: {}
    - Permute: {}
  sup_batch_size: 2
  unsup_batch_size: 2
  shuffle: true
  drop_last: true
  collate_batch: false
  use_shared_memory: false

EvalReader:
  sample_transforms:
    - Decode: {}
    - Resize: {target_size: [640, 640], keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
  batch_size: 2
  shuffle: false
  drop_last: false


TestReader:
  sample_transforms:
    - Decode: {}
    - Resize: { target_size: [640, 640], keep_ratio: False }
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
  batch_size: 1
  shuffle: false
  drop_last: false


pretrain_student_weights: sup005_391.pdparams
pretrain_teacher_weights: sup005_391.pdparams

hidden_dim: 256
use_focal_loss: True
eval_size: [640, 640]

architecture: DETR
DETR:
  backbone: ResNet
  neck: HybridEncoder
  transformer: RTDETRTransformer
  detr_head: DINOHead
  post_process: DETRPostProcess
  post_process_semi: DETRBBoxSemiPostProcess
ResNet:
  # index 0 stands for res2
  depth: 50
  variant: d
  norm_type: bn
  freeze_at: 0
  return_idx: [1, 2, 3]
  lr_mult_list: [0.1, 0.1, 0.1, 0.1]
  num_stages: 4
  freeze_stem_only: True

HybridEncoder:
  hidden_dim: 256
  use_encoder_idx: [2]
  num_encoder_layers: 1
  encoder_layer:
    name: TransformerLayer
    d_model: 256
    nhead: 8
    dim_feedforward: 1024
    dropout: 0.
    activation: 'gelu'
  expansion: 1.0


RTDETRTransformer:
  num_queries: 300
  position_embed_type: sine
  feat_strides: [8, 16, 32]
  num_levels: 3
  nhead: 8
  num_decoder_layers: 6
  dim_feedforward: 1024
  dropout: 0.0
  activation: relu
  num_denoising: 100
  label_noise_ratio: 0.5
  box_noise_scale: 1.0
  learnt_init_query: False

DINOHead:
  loss:
    name: DINOLoss
    loss_coeff: {class: 1, bbox: 5, giou: 2}
    aux_loss: True
    use_vfl: True
    matcher:
      name: HungarianMatcher
      matcher_coeff: {class: 2, bbox: 5, giou: 2}
    use_uni_match: True
DETRPostProcess:
  num_top_queries: 300



SSOD: DETR_SSOD
DETR_SSOD:
  teacher: DETR
  student: DETR
  train_cfg:
    sup_weight: 1.0
    unsup_weight: 1.0
    ema_start_iters:  10000
    pseudo_label_initial_score_thr: 0.9
    min_pseduo_box_size: 0
    concat_sup_data: True
  test_cfg:
    inference_on: teacher



metric: COCO
num_classes: 20
#before train, change voc to coco with voc2coco.py
# partial labeled COCO, use `SemiCOCODataSet` rather than `COCODataSet`
TrainDataset:
  !SemiCOCODataSet
    image_dir: train2017
    anno_path: semi_annotations/instances_train2017.1@5.json
    dataset_dir: dataset/coco
    image_dir: VOC2007/JPEGImages
    anno_path: PseudoAnnotations/VOC2007_trainval.json
    dataset_dir:  dataset/voc/VOCdevkit
    data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']

# partial unlabeled COCO, use `SemiCOCODataSet` rather than `COCODataSet`
UnsupTrainDataset:
  !SemiCOCODataSet
    image_dir: train2017
    anno_path: semi_annotations/instances_train2017.1@5-unlabeled.json
    dataset_dir: dataset/coco
    image_dir: VOC2012/JPEGImages
    anno_path: PseudoAnnotations/VOC2012_trainval.json
    dataset_dir: dataset/voc/VOCdevkit
    data_fields: ['image']
    supervised: False

EvalDataset:
  !COCODataSet
    image_dir: val2017
    anno_path: annotations/instances_val2017.json
    dataset_dir: dataset/coco
    image_dir: VOC2007/JPEGImages
    anno_path: PseudoAnnotations/VOC2007_test.json
    dataset_dir:  dataset/voc/VOCdevkit/
    allow_empty: true
    
epoch: 300 #epoch: 60

LearningRate:
  base_lr: 0.0002
  schedulers:
  - !PiecewiseDecay
    gamma: 1.0
    milestones: [290]
    use_warmup: false
  - !LinearWarmup
    start_factor: 0.001
    steps: 2000

OptimizerBuilder:
  clip_grad_by_norm: 0.1
  regularizer: false
  optimizer:
    type: AdamW
    weight_decay: 0.0001